---
title: metahuman makehuman blender lipsync 动捕 视频转动画 人物模型 捏脸 vroid模型 vrm
created: '2022-09-06T16:11:07.645Z'
modified: '2022-09-07T08:57:45.132Z'
---

# metahuman makehuman blender lipsync 动捕 视频转动画 人物模型 捏脸 vroid模型 vrm

https://github.com/GuijiAI/HeyGem.ai

aigcpanel

tencent comfyui sonic

fay

omnihuman

## 3d models, live2d models and model makers

[makehuman](https://github.com/makehumancommunity/makehuman) as model maker

[avatar sample e](https://vroid.pixiv.help/hc/en-us/articles/360014900273-AvatarSample-E) a cute girl

live2d models from facerig

## blender adapters

[blender vrm importer, exporter and utilities](https://github.com/saturday06/VRM_Addon_for_Blender)

[blender script: vrm to ue4 compatible](https://github.com/MakotoIchinose/VRoid2UE4_BlenderScripts/)

[blender's 'make it pretty' button for vrm models](https://github.com/cmd410/VRoidBones)

[makehuman plugin for blender](https://github.com/makehumancommunity/makehuman-plugin-for-blender)

[blender addon for rhubarb lip sync](https://github.com/scaredyfish/blender-rhubarb-lipsync)

[BlendArMocap](https://github.com/cgtinker/BlendArMocap) by [cgtinker](https://cgtinker.com/) is a Blender add-on to preform Hand, Face and Pose Detection in Blender using just a Webcam built upon Google's Mediapipe. The detected data can be easily transferred to rifigy rigs. 

## lipsync libraries

[rhubarb lip sync](https://github.com/DanielSWolf/rhubarb-lip-sync) is a command-line tool that automatically creates 2D mouth animation from voice recordings

[wav2lip](https://github.com/Rudrabha/Wav2Lip)

## mocap libraries

[openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) is the first real-time multi-person system to jointly detect human body, hand, facial, and foot key-points

[FrankMocap](https://github.com/facebookresearch/frankmocap) A Strong and Easy-to-use Single View 3D Hand+Body Pose Estimator

[EasyMocap](https://github.com/zju3dv/EasyMocap) is an open-source toolbox for markerless human motion capture.

[freemocap](https://github.com/freemocap/freemocap#readme) and its [FAQ wiki](https://github.com/freemocap/freemocap/wiki/FAQ#does-freemocap-work-on-pre-recorded-videos)

FreeMoCap on pre-recorded videos:

Start the RunMe() pipeline at Stage 2, and specify the folder containing the videos you wish to process.

[PARE: Part Attention Regressor for 3D Human Body Estimation](https://github.com/mkocabas/PARE)

[openseeface: face landmark tracking](https://github.com/emilianavt/OpenSeeFace)
