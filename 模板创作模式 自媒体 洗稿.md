---
tags: [idea, paraphraser, template based generator]
title: 模板创作模式 自媒体 洗稿
created: '2022-07-15T05:37:00.000Z'
modified: '2024-02-25T13:32:27.438Z'
---

# 模板创作模式 自媒体 洗稿

在编写抖音文案的时候 用[豆包](https://www.doubao.com)来洗稿 提示词：改写下面的文章 查重率不超过30%

---

媒体的意义和AI类似 别人知道的就不要发了 有可能出错 别人不知道的就发 有可能有用 在兴趣圈周围探索 拓宽视野

## 网页转文章

readbility.js

[pagescraper](https://github.com/Nixes/PageScraper) in php

`elinks -dump <url>`

可以把一个文字或者其他类型的内容当成模板 其他文字 视频 图片当作素材 根据模板收集素材 形成内容 注意素材不能是模板本身 素材不能单一 不然被认定为抄袭

文章洗稿 基于标题和context生成段落：
https://github.com/yangjianxin1/CPM

bert mask:
https://huggingface.co/fnlp/bart-base-chinese
https://huggingface.co/hfl/chinese-macbert-base

chinese paraphrase:
https://github.com/ZhuiyiTechnology/roformer
https://github.com/ZhuiyiTechnology/simbert
[可能不是paraphrase模型](https://github.com/ZhuiyiTechnology/WoBERT)
https://huggingface.co/lijingxin/mt5-for-zh-paraphrase/tree/main
https://huggingface.co/facebook/m2m100_418M
https://github.com/jiangnanboy/chinese_sentence_paraphrase

chinese summarize generator:
一般抽取式的提取 都需要有gpt生成器在中间插入一些句子
[hanlp自带抽取文本方案](https://blog.csdn.net/Thefreelittle/article/details/121342813)
[抽取式文本摘要](https://www.bbsmax.com/A/pRdB0nQGJn/)
[bart t5 pegasus中文文本摘要 有训练数据集](https://github.com/downw/summrization) [训练教程](https://blog.csdn.net/weixin_43718786/article/details/119741580)
一直在想怎么能正确高效的处理seo中，采集的文章怎么去伪原创和洗稿。如果是人工操作的话，那就太麻烦了。采集下来的文章不进行伪原创又害怕被飓风算法命中。

1，tr算法提取摘要再人工重组新的文章。

正好今天发现了python中的textrank4zh库，依赖于jieba、numpy和networkx库，可以通过tr算法进行文章的摘要提取。然后根据摘要再人工洗稿，整合成一篇全新的文章。

测试一篇蚂蜂窝上面的问答，蚂蜂窝问答下面是有很多个答主的内容，通过python爬取所有内容，然后再利用tr算法提取摘要，根据摘要进行重组出一篇新的文章。这样基本上可以成功躲避飓风算法。

先安装依赖库，然后再利用tr4进行摘要提取。

```python
from textrank4zh import TextRank4Keyword, TextRank4Sentence
content = "" # 这里是python采集下来的content html内容
text = re.sub('<.*?>','',content)
text = re.sub(r'\s','',text)
zy = ''
tr4s = TextRank4Sentence()
tr4s.analyze(text=text, lower=True, source = 'all_filters')
# 可修改num值，设置摘要长度。
for item in tr4s.get_key_sentences(num=10): 
  zy = zy + item.sentence
```

2，利用google翻译双向翻译洗稿

之前有接触一个所谓人工智能洗稿的网站小发猫，说的是利用NLP算法进行洗稿，本来我以为洗稿只有同义词替换这个办法。

后来研究了一下小发猫，我首先觉得这个绝对不是利用什么所谓的NLP算法来洗稿，研究了一下发现可能是利用google翻译进行双向翻译，就是先中文翻译英文，然后再拿翻译出来的英文再翻译成中文。

自己也开发了一个这样的伪原创工具，发现其实并不好用。如果不仔细读，这样双向翻译出来的文章还能读，但是仔细读的话。其实语法习惯还有用词根本不准确，甚至有些情况还改变了这句话原有的语义。
