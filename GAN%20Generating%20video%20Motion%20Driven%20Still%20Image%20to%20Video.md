---
created: 2022-05-29T11:52:26+08:00
modified: 2022-08-14T22:30:26+08:00
---

# GAN Generating video Motion Driven Still Image to Video

video animation generation only using few character portraits: æ ¹æ®è§è²è®¾å®å¾ç»åºäººç©å¨ç»ï¼æå¨ç»é©±å¨å¨ï¼
https://github.com/megvii-research/CoNR

galgame video generator using pygameï¼èªå¨åç±»galgameå¨ç»çæå¨ï¼:
https://github.com/w4123/TRPG-Replay-Generator

digan, could generate taichi videos
suggest you to segment video first and then use this to do the freaking work.
https://github.com/sihyun-yu/digan?ref=pythonawesome.com
https://sihyun-yu.github.io/digan/
https://pythonawesome.com/official-pytorch-implementation-of-generating-videos-with-dynamics-aware-implicit-generative-adversarial-networks/

MoCoGAN can generate the same object performing different actions, as well as the same action performed by different objects:
https://github.com/sergeytulyakov/mocogan

still image to talking with hands moving video generation compared to FOMM, can even animate non-human objects:
https://snap-research.github.io/articulated-animation/

montage.ai generate video by music with deep analyzer:
https://github.com/Tartar-san/montage.ai

tiktok hashtag montage: 
https://github.com/andreabenedetti/tiktok-montage
