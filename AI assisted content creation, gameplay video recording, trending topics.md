---
title: 'AI assisted content creation, gameplay video recording, trending topics'
created: '2024-03-10T14:08:10.000Z'
modified: '2025-02-03T18:16:44.359Z'
---

# AI assisted content creation, gameplay video recording, trending topics

video translation

https://github.com/Huanshere/VideoLingo

---

https://github.com/lyogavin/airllm

super large llm inference

---

https://github.com/tensorlakeai/indexify

unstructured data indexing

---

terminal ai utility `sgpt`

https://github.com/TheR1D/shell_gpt

---

code to video

https://github.com/redotvideo/revideo

---

fishaudio voice cloning

[omniparse](https://github.com/adithya-s-k/omniparse) data serialization

---

Video understanding and video embedding can be achieved with ViViT (in huggingface).

[Video generation agent tutorial](https://www.bilibili.com/read/cv33613833/)

[MoneyPrinterTurbo](https://github.com/harry0703/MoneyPrinterTurbo)

---

[Mini Gemini](https://github.com/dvlab-research/MGM)

---

Use [enhancr](https://github.com/mafiosnik777/enhancr) for frame interpolation, super resolution and scaling. The pro version contains faster models.

The app is built using [electron forge](https://www.electronforge.io/config/configuration).

Interpolation gets worse with higher resolution, that's why I wouldn't upscale first.

enhancr is built upon the following models:


## Interpolation

>**RIFE (NCNN)** - [megvii-research](https://github.com/megvii-research)/**[ECCV2022-RIFE](https://github.com/megvii-research/ECCV2022-RIFE)** - powered by [styler00dollar](https://github.com/styler00dollar)/**[VapourSynth-RIFE-NCNN-Vulkan](https://github.com/styler00dollar/VapourSynth-RIFE-NCNN-Vulkan)**

>**RIFE (TensorRT)** - [megvii-research](https://github.com/megvii-research)/**[ECCV2022-RIFE](https://github.com/megvii-research/ECCV2022-RIFE)** - powered by [AmusementClub](https://github.com/AmusementClub)/**[vs-mlrt](https://github.com/AmusementClub/vs-mlrt)** & [styler00dollar](https://github.com/styler00dollar)/**[VSGAN-tensorrt-docker](https://github.com/styler00dollar/VSGAN-tensorrt-docker)**

>**GMFSS - Union (PyTorch/TensorRT)** - [98mxr](https://github.com/98mxr)/**[GMFSS_Union](https://github.com/98mxr/GMFSS_union)** - powered by [HolyWu](https://github.com/HolyWu)/**[vs-gmfss_union](https://github.com/HolyWu/vs-gmfss_union)**

>**GMFSS - Fortuna (PyTorch/TensorRT)** - [98mxr](https://github.com/98mxr)/**[GMFSS_Fortuna](https://github.com/98mxr/GMFSS_Fortuna)** - powered by [HolyWu](https://github.com/HolyWu)/**[vs-gmfss_fortuna](https://github.com/HolyWu/vs-gmfss_fortuna)**

>**CAIN (NCNN)** - [myungsub](https://github.com/myungsub)/**[CAIN](https://github.com/myungsub/CAIN)** - powered by [mafiosnik](https://github.com/mafiosnik777)/**vsynth-cain-NCNN-vulkan** (unreleased)

>**CAIN (DirectML)** - [myungsub](https://github.com/myungsub)/**[CAIN](https://github.com/myungsub/CAIN)** - powered by [AmusementClub](https://github.com/AmusementClub)/**[vs-mlrt](https://github.com/AmusementClub/vs-mlrt)**

>**CAIN (TensorRT)** - [myungsub](https://github.com/myungsub)/**[CAIN](https://github.com/myungsub/CAIN)** - powered by [HubertSotnowski](https://github.com/HubertSotnowski)/**[cain-TensorRT](https://github.com/HubertSotnowski/cain-TensorRT)**


## Upscaling

>**ShuffleCUGAN (NCNN)** - [styler00dollar](https://github.com/styler00dollar)/**[VSGAN-tensorrt-docker](https://github.com/styler00dollar/VSGAN-tensorrt-docker)** - powered by [AmusementClub](https://github.com/AmusementClub)/**[vs-mlrt](https://github.com/AmusementClub/vs-mlrt)**

>**ShuffleCUGAN (TensorRT)** - [styler00dollar](https://github.com/styler00dollar)/**[VSGAN-tensorrt-docker](https://github.com/styler00dollar/VSGAN-tensorrt-docker)** - powered by [AmusementClub](https://github.com/AmusementClub)/**[vs-mlrt](https://github.com/AmusementClub/vs-mlrt)**

>**RealESRGAN (NCNN)** - [xinntao](https://github.com/xinntao)/**[Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN)** - powered by [AmusementClub](https://github.com/AmusementClub)/**[vs-mlrt](https://github.com/AmusementClub/vs-mlrt)**

>**RealESRGAN (DirectML)** - [xinntao](https://github.com/xinntao)/**[Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN)** - powered by [AmusementClub](https://github.com/AmusementClub)/**[vs-mlrt](https://github.com/AmusementClub/vs-mlrt)**

>**RealESRGAN (TensorRT)** - [xinntao](https://github.com/xinntao)/**[Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN)** - powered by [AmusementClub](https://github.com/AmusementClub)/**[vs-mlrt](https://github.com/AmusementClub/vs-mlrt)**

>**RealCUGAN (TensorRT)** - [bilibili](https://github.com/bilibili)/**[ailab/Real-CUGAN](https://github.com/bilibili/ailab/tree/main/Real-CUGAN)** - powered by [AmusementClub](https://github.com/AmusementClub)/**[vs-mlrt](https://github.com/AmusementClub/vs-mlrt)**

>**SwinIR (TensorRT)** - [JingyunLiang](https://github.com/JingyunLiang)/**[SwinIR](https://github.com/JingyunLiang/SwinIR)** - powered by [mafiosnik777](https://github.com/mafiosnik777)/**SwinIR-TensorRT** (unreleased)

## Restoration

>**DPIR (DirectML)** - [cszn](https://github.com/cszn)/**[DPIR](https://github.com/cszn/DPIR)** - powered by [AmusementClub](https://github.com/AmusementClub)/**[vs-mlrt](https://github.com/AmusementClub/vs-mlrt)**

>**DPIR (TensorRT)** - [cszn](https://github.com/cszn)/**[DPIR](https://github.com/cszn/DPIR)** - powered by [AmusementClub](https://github.com/AmusementClub)/**[vs-mlrt](https://github.com/AmusementClub/vs-mlrt)**

>**SCUNet (TensorRT)** - [cszn](https://github.com/cszn)/**[SCUNet](https://github.com/cszn/SCUNet)** - powered by [mafiosnik777](https://github.com/mafiosnik777)/**SCUNet-TensorRT** (unreleased)


---

Kdenlive has many video editing features, like automatic scene split, video stabilzation.

---

To extract existing hard-coded subtitles in videos, use [videosubfinder](https://sourceforge.net/projects/videosubfinder/), which is used in Cradle, an Red Dead Redemption II agent.

---

To check if audio is recorded, we can view amplitude instead of hearing.

```bash
ffprobe -f lavfi -i "amovie=<audio_or_video_filepath>,astats=metadata=1:reset=1" -show_entries frame=pkt_pts_time:frame_tags=lavfi.astats.Overall.RMS_level -of default=noprint_wrappers=1:nokey=1 -sexagesimal -v error
```

---

[AI toolbox](https://github.com/OceanNg529/allAI): a comprehensive content creation toolbox with links to related projects

---

Use `streamlit` to write interactive interfaces for video labeling, editing and registration, tracking viewer counts.

Grided image can be used for image selection prompting and image condensation, putting multiple images together to save processing power during tasks like video rating.

When you play video games on low end devices, you can tune down the resolution and image quality, to ensure 30 FPS.

If you change screen resolution during screen recording, you might lose your view.

Train a video grading system with recent and relevant video grades, and when evaluating put grading context into the prompt, thus generalize the system.

Get system predicted labels of video content to train a label predictor out of it, providing necessary context of test video for improving the grading system accuracy.

[Taskmatrix](https://github.com/moymix/TaskMatrix) is a multimodal agent framework suitable for multiple types of image editing, using diffusion models.

You can learn what the viewers are craving about via recommendation engines, dynamic posts and latest bangumi releases.

Post the same content across multiple platforms to increase view counts.
