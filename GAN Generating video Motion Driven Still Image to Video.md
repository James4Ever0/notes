---
tags: [motion driven video, music to video, video generator]
title: GAN Generating video Motion Driven Still Image to Video
created: '2022-05-29T03:52:26.000Z'
modified: '2022-09-17T11:33:37.205Z'
---

# GAN Generating video Motion Driven Still Image to Video

[thin plate spline motion model](https://github.com/yoyo-nb/thin-plate-spline-motion-model)

video animation generation only using few character portraits: 根据角色设定图画出人物动画（有动画驱动器）
https://github.com/megvii-research/CoNR

galgame video generator using pygame（自动化类galgame动画生成器）:
https://github.com/w4123/TRPG-Replay-Generator

digan, could generate taichi videos
suggest you to segment video first and then use this to do the freaking work.
https://github.com/sihyun-yu/digan?ref=pythonawesome.com
https://sihyun-yu.github.io/digan/
https://pythonawesome.com/official-pytorch-implementation-of-generating-videos-with-dynamics-aware-implicit-generative-adversarial-networks/

MoCoGAN can generate the same object performing different actions, as well as the same action performed by different objects:
https://github.com/sergeytulyakov/mocogan

still image to talking with hands moving video generation compared to FOMM, can even animate non-human objects:
https://snap-research.github.io/articulated-animation/

montage.ai generate video by music with deep analyzer:
https://github.com/Tartar-san/montage.ai

tiktok hashtag montage: 
https://github.com/andreabenedetti/tiktok-montage
